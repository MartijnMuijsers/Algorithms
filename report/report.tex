\documentclass[11pt]{article}

\usepackage{amsmath,amssymb}
\usepackage{a4wide}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{parskip}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{gensymb}

\newcommand{\maxsize}[1]{\begin{quotation} {\sl \noindent Maximum size: #1.} \end{quotation}}

\newcommand{\crp}[1]{\begin{quotation} {\sl \noindent For the curve- and network-reconstruction problem: #1} \end{quotation}}

\newcommand{\example}[1]{\begin{quotation} {\sl \noindent Example: #1} \end{quotation}}

%%
% Theorem-Like Environments
%
\newtheorem{defin}{Definition}
  \newenvironment{mydefinition}{\begin{defin} \sl}{\end{defin}}
\newtheorem{theo}[defin]{Theorem}
  \newenvironment{mytheorem}{\begin{theo} \sl}{\end{theo}}
\newtheorem{lem}[defin]{Lemma}
  \newenvironment{lemma}{\begin{lem} \sl}{\end{lem}}
\newtheorem{coro}[defin]{Corollary}
  \newenvironment{corollary}{\begin{coro} \sl}{\end{coro}}
\newtheorem{obse}[defin]{Observation}
  \newenvironment{observation}{\begin{obse} \sl}{\end{obse}}

\newenvironment{proof}{\emph{Proof.}}{\hfill $\Box$ \medskip\\}

% TODO(robwu): Choose a more descriptive title
\title{2D curve and network reconstruction}
\author{
A. van den Boogaart \and
W. Brouwer \and
C. Mens \and
M. Muijsers \and
R. Wu
}
\date{\today}

\begin{document}

\newpage

\maketitle

\begin{abstract}
In this study  two formulations of solutions to effectively solve the problem of connecting a set of nodes in the 2D plane in an aesthetically pleasing manner, and one formulation of a solution for reconstructing a road network from a set of nodes in the 2D plane are proposed.
The first proposed solution reconstructs these nodes into a single curve.
The second proposed solution will yield a similar result as the first solution, but will distinguish multiple curves from one another.
The third proposed solution attempts to create a road network from nodes. This problem is distinct from the other two, as here the challenge lies in creating intersections, instead of avoiding them.

\end{abstract}

\section{Introduction}
\label{se:introduction}
The to be presented algorithms will solve the problem of reconstructing curves for a given set of points in the 2D plane. This problem has three slightly different forms: The first two require the reconstruction of a set of points into curves, in the first case there is only one curve, whereas in the second case there are multiple. The third part of the problem requires reconstructing to a road network.

To be able to focus on a specific type of curve reconstruction, we will only consider curves where all points in the input are used and where line segments do not intersect each other.

The goal of the road network algorithm is to create a reasonable representation of the road network, such that a person would agree with the representation that the algorithm gives. This algorithm could be used to create a road map from the given data.

As with the other two algorithms, we have created some constraints for the road network to be able to focus on specific input. All points need to have at least one possible path to every other point and intersecting lines need an additional node at the intersection. The nodes are points in a 2D plane. In practice, the generation of nodes can be done by laser scanners, or in the case of the road network, by following roads and giving a gps location at certain intervals.

There are multiple known solutions to these problems. One of these is `The Crust Algorithm' \cite{crust}, which first creates a Voronoi diagram, then uses Delaunay triangulation between the Voronoi diagram and the Voronoi vertices. The Crust Algorithm works well in three dimensions, but has difficulty with detecting sharp corners which are common in two dimensional reconstruction.
A different algorithm, specifically made for two dimensional reconstruction is `Gathan' \cite{gathan}. This provides a good solution for general cases, but does not allow for selecting multiple or single curves and relies on difficult mathematical graphs.
DISCUR \cite{discur} is another algorithm solving the curve reconstruction problem. It has no parameters, but requires dense sampling points to recontruct correctly.
For the network problem there exists a road network reconstruction algorithm \cite{chen} which obtains subcurves by creating a voronoi diagram.

Delaunay triangulation could possibly be used to create a relatively small set of edges for the third problem, after which a rectilinear spanning graph or straight lines can be determined between points. This will improve efficiency, as it has a running time of $O(n \log{n})$, whereas Kruskal's algorithm will check all possible edges initially, resulting in $O(n^2 \log{n})$.

For the single curve reconstruction problem, we have also looked at the convex hull \cite{convex}. A convex hull will create segments between all the outermost points, such that no unconnected point is outside of the enclosed area. Like putting a rubber band around all the points. This is useful for the outermost nodes, but does not do anything with the nodes inside this outline.

For solving these three problems, we present an algorithm for each problem.
To solve the single curve reconstruction problem, the algorithm creates a convex hull and then continues by removing the largest edge and then reconnecting the figure by creating 2 new segments with another nearby point.
Multiple curves are solved using a seperate algorithm, which first connects the shortest segments such that there are no intersecting lines, after which it will seek out sharp angles and tries to remove and replace these with obtuse angles.
The road network reconstruction problems is solved using a minimum spanning tree. After reconstructing this tree, the algorithm finds nodes with degree 1 and connects these to a nearby node. To correctly create intersections, nodes with degree 3 or higher will check their surrounding segments and will add a point based on their angles.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.3]{images/outputOverview.png}
\caption{Output of the single curve (Left), multiple curve (Middle) and Network (Right) reconstruction algorithms.}
\label{outputOverview}
\end{figure}$ $\\


\section{The algorithms}
\label{se:algorithms}
\subsubsection{Background definitions}
Let $U = [0,1]^2$ be a set of points in a two-dimensional space.
For any $u,v \in U$, the line segment between $u$ and $v$ is denoted as $s_{u,v}$. $u$ and $v$ are called the endpoints of $s_{u,v}$. Each of the presented algorithms take $P \subset U$ as input, and output $S \subset \{s_{p,q} | p,q \in P \land p \neq q \}$.
 Two distinct points $a$ and $b$ are called \textit{connected} if there is a segment in $S$ whose endpoints are $a$ and $b$.
 Two segments are \textit{intersecting} each other if the line segments have a common point besides than the endpoints.
%TODO (rob): The next line does not belong here, it's a detail specific to the algorithm, right?
%None of these output line segments intersect another line segment in $S$.

For any $p,q \in U$, $d(p,q)$ is the Euclidean distance between $p$ and $q$. %\ref{todo:euclid_distance}.

For every $p \in P$ and $n \in \mathbb{N}$, $Adj_{p,n}$ is an adjacency list consisting of the $n$ nearest points to $p$, sorted in ascending order.

For any $p \in P$, the degree of $p$ denoted by $deg(p)$ is the number of line segments that are connected to $p$.

$\varphi(s_{u,v}, s_{v_w})$ is the absolute value of the smallest angle between two segments that share a common point,
If $p \in P$ has degree two, then $\alpha_p$ is defined to be the absolute value of the smallest angle between its two connected segments. %TODO What if degree is not two?



\subsection{Single curve reconstruction}
\subsubsection{Description}
For a given set of $n$ points $P \subset U$, this algorithm attempts to generate a set of non-intersecting line segments $S$ such that:

\noindent\begin{enumerate}\topsep=0pt\itemsep=0pt\parsep=0pt
\item $\forall p \in P : deg(p) \leq 2$
\item The segments in $S$ do not intersects each other
\end{enumerate}

Furthermore, the algorithm will conform to the following in a good-case scenario:

\noindent\begin{enumerate}\topsep=0pt\itemsep=0pt\parsep=0pt
\item The segments form an open or closed curve, i.e. $\#S = n-1 \vee \#S = n$
\end{enumerate}

The algorithm is based on the idea that a single curve always outlines some concave polygon, and thus can be gotten by starting with an outline of the points and collapsing this outline onto the other points to wrap a curve around a polygon containing all the points.

Collapsing an outline to wrap it around all points means all points must be inside the polygon defined by that outline. For this purpose, we start with the boundary of the convex hull as our initial set of segments. To compute the convex hull, we will use Graham's scan, an algorithm that finds all vertices of the convex hull ordered along its boundary.

The algorithm thus begins by creating a set $S$ of segments that are the boundary of the convex hull of $P$. We will now define a likelihood function, for which two existing possibilities are listed below:

\noindent\begin{enumerate}\topsep=0pt\itemsep=0pt\parsep=0pt
\item $s_{u,v} \in S \wedge p \in P \Rightarrow likelihood(s_{u,v}, p) = d(u, v)*d(u, v)/(d(p, v)*d(p, v)+d(p, u)*d(p, u))$
\item $s_{u,v} \in S \wedge p \in P \Rightarrow likelihood(s_{u,v}, p) = d(u, v)/d(p, v)+d(p, u))$
\end{enumerate}

Then, let $Q = \{ p \in P | \neg ( \exists v \in P \exists s_{p,v} \}$. Then $\#Q = n - \#S$.

After the convex hull boundary vertices are found, we start repeating the following procedure until $\#Q = 0$:

\begin{enumerate}
\item Let $p \in P$ be a point and $s_{u,v} \in S$ be a segment so that $q \in P \wedge t \in S \Rightarrow likelihood(s_{u,v}, p) \geq likelihood(t, q)$
\item Remove $s_{u,v}$ from $S$
\item Add $s_{u, p}$ to $S$
\item Add $s_{v, p}$ to $S$
\item Remove $p$ from $Q$
\end{enumerate}

This way, a curve (defined by the segments in $S$) is gotten with exactly as many segments as there were points given (per point removed from $Q$, we end up with one more segment in $S$, resulting in $\#S = n$).

Now however, we may end up with segments that intersect each other, and segments that are too long and should be better replaced by a gap. To take these matters into account, the algorithm then removes all lines which seem inappropriate, choosing to remove lines that are unexpected in length or intersect with others.

Now, let $l1(S)$ be the longest segment so that $l1(S) \in S$, and let $l2(S)$ be the longest segment so that $l2(S) \in S \setminus { l1(S) }$. Then it is wanted to remove all segments that could be too long by comparing the factor between the top two longest segments to some parameter $k$:

\begin{enumerate}
\item While $l1(S) \geq k \cdot l2(S)$, remove $l1(S)$ from $S$
\end{enumerate}

Then, the algorithm removes any intersections left, by removing the segments that have intersections in order of number of intersections:

\begin{enumerate}
\item Let $s \in S \Rightarrow I(s) = \{ t \in S | s$ intersects with $t \}$. Then, until $s \in S \Rightarrow \#I(s) = 0$, remove $r$ from $S$, where $s \in S \Rightarrow \#I(s) \leq \#I(r)$
\end{enumerate}

This of course can cause a great loss of size of $S$. If there are segments $s_{u,v}$ such that $deg(u) = 1$, $deg(v) = 1$, $\neg ( s_{u,v} \in S )$ then $s_{u,v}$ could be a good candidate to add to $S$. The algorithm will, in an attempt to repopulate $S$, add any such segments $s_{u,v} \in MST(P) $, where $MST(P)$ denotes the set of segments representing a minimum spanning tree of $P$. Then again, an unwantedly long segment may have been re-added, so to prevent this from showing in the final result, the algorithm tries to remove a segment that seems too long one more time:

\begin{enumerate}
\item If $l1(S) \geq k \cdot l2(S)$, remove $l1(S)$ from $S$
\end{enumerate}

A basic implementation of the algorithm requires $O(n^2)$ time (assuming a running time of a Graham scan implementation of $O(n\log(n))$ and a running time of a minimum spanning tree implementation of $O(n\log(n))$. It may run using $O(n^2)$ or $O(n)$ storage, depending on how the likelihoods are compared. If memory is slow, an index of likelihoods from every segment in $S$ to every point in $Q$ can be kept and updated, resulting in $O(n^2)$ storage. Otherwise, these likelihoods can be recalculated when needed, resulting in $O(n)$ storage.

\subsection{Multiple curve reconstruction}
\subsubsection{Description}
For a given set of $n$ points $P \subset U$, this algorithm generates a set of non-intersecting line segments $S$ such that for every point, its degree is at most two. This result is generated in two steps. The segments in $S$ connect points in $P$ and form one or more shapes.

During both steps, two invariants are maintained:%
\noindent\begin{enumerate}\topsep=0pt\itemsep=0pt\parsep=0pt
\item $\forall p \in P : deg(p) \leq 2$
\item The segments in $S$ do not intersect each other.
\end{enumerate}

%First, a set of segments is generated from the input. From this set, the shortest segments are selected and added to $S$ if the invariants are not invalidated. More precisely:

%TODO Arjan said that it would be a good idea to first explain how T is generated before stating how it is used.
Let $T \subset \{s_{p,q} | p,q \in P \land p \neq q \}$. A segment $s_{shortest}$ is said to be the shortest segment if there is no other segment in $T$ whose length is smaller than the length of $s_{shortest}$.
While $T$ is not an empty set, find $s_{shortest}$ and remove it from the set and add $s_{shortest}$ to $S$ if doing so does not invalidate the invariants. Repeat this step until $T$ is empty.
%TODO Early termination is also possible when $S$ has $n$ elements.

%TODO Justify previous method.

The elements for set $T$ can be generated in two ways. A straight-forward approach is to create a list of all possible segments, sort the list and iterate through it. The number of possible segments is $(n-1)^2$, so the memory complexity is $O(n^2)$. Sorting time is linearithmic in terms of the number of elements to sort, so the time complexity is $O(n^2\log(n))$.

A quadratic complexity for memory is highly undesirable, because most computer systems have a limited amount of memory. To reduce the memory requirements, the first step can also be calculated using the following alternative method. For each point $p \in P$, find the $m$ nearest points and store the segments that are constructed from these points in a list. Then as before sort the list and iterate through its elements.

With this alternative method, the memory complexity is reduced to $O(mn)$. The $m$ nearest points can be found in $O(mn)$ time with partial selection sort.
%TODO Add reference for partial selection sort.
 $mn$ segments will thus be generated in $O(mn^2)$ time and sorted in $O(mn\log(mn))$ time. If $m$ is a (small) constant, then the memory complexity is $O(n)$ and the time complexity is $O(n\log(n))$. This is a huge improvement over the previous algorithm! The disadvantage of this method over the previous is that a dense cluster of $m$ points will never be connected to other points and leave gaps in a curve.

This first step only accounts for the lengths of the segments, not for any other properties of the shapes in the graph, such as the angle between two segments. Consequently, there may be points with two connected segments that have a small angle. An initial experimental evaluation showed that this first step of the algorithm yields a reasonable solution, but tends to create small and disconnected shapes. This is not surprising, because in a sparse graph nodes in a corner are often close to each other. Consequently, the segments of the initial solution often form a set of small shapes, as seen in figure \ref{fig:multiple_initial_solution}.

\begin{figure}[hbtp]
\centering
\begin{subfigure}{.33\linewidth}
  \centering
  \includegraphics[width=0.9\linewidth]{multiplecurves/algo_step0_dots.pdf}
  \caption{Input}
\end{subfigure}%
\begin{subfigure}{.33\linewidth}
  \centering
  \includegraphics[width=0.9\linewidth]{multiplecurves/algo_step1_add_lines_with_numbers.pdf}
  \caption{Initial solution}
\end{subfigure}%
  \caption{Input and output of the multiple curve algorithm's first step.}
\label{fig:multiple_initial_solution}
\end{figure}

In the next step, disconnected shapes are joined if possible, by replacing segments in $S$ that are part of a corner with a sharp angle. Since the previous step yields a good initial solution, most of the segments will not be modified, so the angles at the endpoints of most segments will not change. This observation is important, because replacing a segment affects the angles of the segments that are connected to the former and new endpoints of the replaced segment, which could invalidate a previous calculation that relied on the angles.

For every $p \in P$ where $deg(p) = 2$, select $p$ for the next step of the algorithm if $\alpha_p < \alpha_{required}$. $\alpha_{required}$ is a parameter that is used to determine whether an angle is considered to be too sharp. It is set to $90\degree$.

For each of the selected points, try to replace a segment as follows:

\begin{enumerate}
\item Let $p_1$ be the selected point, and $s_{p_1,p_2}$ be the longest segments that is connected to $p_1$. The other segment is connected to $p_3$.
\item Select the best point from $Adj_{p_1,10}$. The best point is found by following the next steps for each $q_1 \in Adj_{p_1,10}$.
  \begin{enumerate}
  \item If $deg(q_1) = 0$, then $q_1$ is not the best point.
  \item Let $q_2$ be a point that is connected with $q_1$. If $deg(p_1) = 2$, repeat the same steps from here for the endpoint of the other segment.
  \item If $\varphi(s_{p_1,p_3}, s_{p_1,q_1}) < \alpha_{sharp}$, then $q_1$ is not the best point. $\alpha_{sharp}$ is a parameter that specifies the minimum required angle. This step exists to prevent inserting sharp corners again. This parameter is typically lower than $\alpha_{required}$ and is set to $45\degree$.
  \item If $d(p_1, q_1)$ and $d(p_2,q_2)$ are both greater than $d(p_1,p_3) \cdot \lambda$, then $q_1$ is not the best point.
  This step ensures that a segment is not replaced by segments that are significantly shorter.
  Parameter $\lambda$ is set to $1.2$ to allow points that result in a slightly shorter segment to be considered as best point.
  \item If $s_{q_1,q_2}$ is already in $S$, and (indirectly) connected to $p_1$, then $q_1$ is not the best point. This step exists to avoid breaking shapes in even smaller shapes. Since the degree of every point is at most two, this can easily be checked by enumerating the segments in the paths originating from $p_1$.
  \item If any of the new segments is close to the endpoints of the other new segment, then $q_1$ is not the best endpoint. A point is close to a line segment if the length of the line segment is greater than the distance between the point and the segment multiplied by parameter $\textsc{ClosenessFactor}$ (set to $5$).
  \item If any of the new segments intersect each other or other segments in $S$ (besides the to-be-removed ones), then $q_1$ is not the best point.
  \item Otherwise, $q_1$ is the best point if $d(p_1,q_1) + d(p_2,q_2) - d(p_1,p_2) - d(q_1,q_2)$ is minimal (relative to all other $q \in Adj_{p_1,10}$), \textit{and} greater than $\textsc{minWeight}$. This parameter specifies the threshold for the weight. A positive value means that the sum of the new segment's lengths must be smaller than the existing segments, while a negative value means that the sum is allowed to be bigger. $\textsc{minWeight}$ is set to $-0.2$.
  \end{enumerate}

\item If the best point $q_1$ exists, remove $s_{p_1,p_2}$ and $s_{q_1,q_2}$ from $S$, and add $s_{p_1,q_1}$ and $s_{p_2,q_2}$ to $S$.
\item Otherwise the longest segment cannot be replaced, so check whether the shortest segment can be replaced by repeating these steps with the shortest segment instead of the longest one.
\end{enumerate}


The meaning and relations between $p_1$, $p_2$, $p_3$, $q_1$ and $q_2$ are displayed in figure \ref{fig:multiple_pppqq}.
Let $n$ be the size of $P$. Since $|S| \leq |P|$, $|P| = O(n)$.
In the worst case, the algorithm checks for each segment whether it needs to be replaced. At each check, the best choice is select among the 10 nearest points (found in linear time using partial selection sort). This takes $O(n)$ time, because after spending a constant amount of time on determining the weight, $O(n)$ time is required to check for intersections. Thus the time complexity is $O(n^2) = O(n^2)$. The storage complexity is constant.

If the first method of step 1 is used, then the full algorithm requires $O(n^2)$ storage and $O(n^2\log(n))$ time. If the alternative method is used, then the algorithm runs in $O(n^2)$ time using $O(n)$ storage.

\begin{figure}[hbtp]
\centering
\begin{subfigure}{.33\linewidth}
  \centering
  \includegraphics[width=0.9\linewidth]{multiplecurves/algo_replace_segment.pdf}
  \caption{Initial solution}
\end{subfigure}%
\begin{subfigure}{.33\linewidth}
  \centering
  \includegraphics[width=0.9\linewidth]{multiplecurves/algo_final.pdf}
  \caption{Final solution}
\end{subfigure}%
  \caption{$s_{p_1,p_2}$ and $s_{q_1,q_2}$ is replaced with $s_{p_1,q_1}$ and $s_{p_2,q_2}$.}
\label{fig:multiple_pppqq}
\end{figure}


\subsection{Network Algorithm}
%TODO Chris: Insert content of network2.tex.

\section{Experimental evaluation}
\subsection{Generating input}
To properly test the presented algorithms, many test cases have been created. The majority of these test cases were created by hand, made to be as difficult as possible for the algorithms. Some have sharp corners, or have points with large gaps between them as shown in figure \ref{single}.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.2]{anglesamplerate.png}
\caption{Test case with low sampling and a sharp angle (left) and the resulting output from the single curve algorithm (right.)}
\label{single}
\end{figure}

Other test cases have been created to test the running time of the algorithm, with the amount of nodes ranging from $100$ to $10000$. This same input is then used on all algorithms.

\begin{table}[ht!]
    \begin{tabular}{lrrrrr}
    ~                       & 100 nodes & 500 nodes & 1.000 nodes & 5.000 			nodes & 10.000 nodes \\
    Single Reconstruction   & 33ms      & 126ms     & 782ms       & 3.985ms     	& 20.604ms     \\
    Multiple Reconstruction & 38ms      & 146ms     & 207ms       & 2.947ms     	& 7.387ms      \\
    Network Reconstruction  & 18ms      & 85ms      & 143ms       & 1.996ms     	& 4.802ms      \\
    \end{tabular}
\caption{Table showing the computing time required for different input sizes.}
\end{table}

The multiple curve algorithm has additional test cases that are not run by the single curve algorithm, made specifically to test whether it correctly distinguishes between the multiple curves. These include curves enclosed in another curve, some curves that are close to each other and multiple curves that spiral around each other, some examples of these test cases are given in figure \ref{multi}.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.3]{multiInput.png}
\caption{A collection of test cases specifically for the multiple curve algorithm, with the correct output displayed to the right of it.}
\label{multi}
\end{figure}

The network algorithm has different input than the other two given curve reconstruction algorithms, so it therefore also requires specific test cases. For this, test cases have been modeled after real life road maps. Some test have also been created to test specific parts of the algorithm, for instance a inputs that has close parallel lines, merging roads and roundabouts.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.3]{networkInput.png}
\caption{A large intersection to test for parallel and merging lines (Left) Simple neighbourhood (Right)}
\label{network}
\end{figure}$ $\\

\subsection{Resulting output}
Dingen die je erin kan zetten:\\
Parameters, input sizes, sampling conditions, wat niet werkt en waarom niet, allemaal met plaatjes/tabellen erbij. Geef ook aan hoe je de werking van het algoritme kan zien in de output.

\subsubsection{Single curve}
The single curve algorithm strongly depends on the ability of the likelihood function to accurately measuring how effective the resulting change would be. In the specifics of the algorithm, a segment is routinely removed and replaced by two new segments. This should contribute to a positive change in the curve. Clearly, the likelihood should increase when the two new segments are more like the old one. The triangle inequality gives the interesting opportunity to define the likelihood as follows (as noted earlier), while taking into account the angle between the old segment and the new segments, as well as their ratio in length:

\noindent\begin{enumerate}\topsep=0pt\itemsep=0pt\parsep=0pt
\item $s_{u,v} \in S \wedge p \in P \Rightarrow likelihood(s_{u,v}, p) = d(u, v)*d(u, v)/(d(p, v)*d(p, v)+d(p, u)*d(p, u))$
\item $s_{u,v} \in S \wedge p \in P \Rightarrow likelihood(s_{u,v}, p) = d(u, v)/d(p, v)+d(p, u))$
\end{enumerate}

\subsubsection{Multiple curves}
The accuracy of the multiple curve algorithm relies on the effectiveness of the initial solution. The description provided two ways to reach the initial solution. The original method is relatively expensive, so the alternative method was made available to make the algorithm feasible for bigger input sizes. In the next section, the experimental results of the initial solution are evaluated. Then, the transformation from the initial solution to the final solution is evaluated.

Since the initial solution is created by taking the shortest of all possible line segments, the algorithm works perfect for curves where the points are uniformly distributed over the lines of the desired figure.
In figure \ref{fig:exp:multiple_initial}, the two initial solutions are displayed for an input of points that resembles three closed curves. Although the points are not uniformly distributed, the initial solution \ref{fig:exp:multiple_initial:initial} is perfect, because the points of the individual curves are closer to each other than the points of the other curves.
The alternative initial solution \ref{fig:exp:multiple_initial:alternative} has four unconnected points. Each of the four points are far apart from each other, with the points in the center being among their nearest 10 neighbours. Since the alternative algorithm does not look past the 10 nearest neighbours, the other free points are not visible to the algorithm and therefore they remain disconnected.
The fact that these points are not connected is not necessarily bad. After all, one can argue that a snapshot of four points does not justify the creation of a sparse curve that is larger than the other curves that consist of many more points.

The alternative solution only selects a number of points in the neighbourhood of a point. When the number of neighbors is too small, many of the input points remain disconnected. The imperfect initial solution \ref{fig:exp:multiple_initial:alternative} can be resolved by doubling the number of neighbors, but the same problem would show up again if the density of the curves in the middle is doubled as well. Since this problem cannot be solved by increasing the number of neighbors, a practical number of neighbors is chosen.
Experiments show that using the 10 nearest neighbours is sufficient to get an accurate initial solution.

\begingroup
\tikzset{every picture/.style={scale=1,radius=0.05,line width=0.4,rotate=90}}%
\begin{figure}[ht!]
\centering
\begin{subfigure}{.33\linewidth}
\centering
\input{tikz/final_multiple_input.tex}
\caption{Input}
\label{fig:exp:multiple_initial:input}
\end{subfigure}%
\begin{subfigure}{.33\linewidth}
\centering
\input{tikz/final_multiple_output.tex}
\caption{Initial solution}
\label{fig:exp:multiple_initial:initial}
\end{subfigure}%
\begin{subfigure}{.33\linewidth}
\centering
\input{tikz/final_multiple_output_alternative.tex}
\caption{Alternative initial solution}
\label{fig:exp:multiple_initial:alternative}
\end{subfigure}
\caption{The initial solutions for three curves}
\label{fig:exp:multiple_initial}
\end{figure}
\endgroup

Figure \ref{fig:exp:multiple_split_triangles:initial} shows an initial solution that consists of 4 curves. The solution looks reasonable, but note that three of these curves are triangles with a very sharp corner. This is a very typical initial solution, caused by the fact that only lengths of the segments are used in the first step of the algorithm. After connecting the three points at the bottom of picture \ref{fig:exp:multiple_split_triangles:initial:input}, all of the three points have degree two and will no longer accept connections with other points, even though two of these points are very close to the left and right points (which also form a triangle, ultimately).

This problem of generating triangles is very common, and sufficiently solved by the second step of the algorithm, as seen in figure \ref{fig:exp:multiple_split_triangles:output}. All triangles have been identified and merged into one big curve. Not entirely coincidentally, this example shows that the removed segments are the longest segments within the triangle. This happens quite often, because the triangle problem is caused by abusively connecting one endpoint of a short curve with the other endpoint of the same short curve.

\begingroup
\tikzset{every picture/.style={scale=1,radius=0.05,line width=0.4,rotate=90}}%
\begin{figure}[ht!]
\centering
\begin{subfigure}{.33\linewidth}
\centering
\input{tikz/final_split_triangles_input.tex}
\caption{Input}
\label{fig:exp:multiple_split_triangles:initial:input}
\end{subfigure}%
\begin{subfigure}{.33\linewidth}
\centering
\input{tikz/final_split_triangles_initial.tex}
\caption{Initial solution}
\label{fig:exp:multiple_split_triangles:initial}
\end{subfigure}%
\begin{subfigure}{.33\linewidth}
\centering
\input{tikz/final_split_triangles_output.tex}
\caption{Final solution}
\label{fig:exp:multiple_split_triangles:output}
\end{subfigure}
\caption{The final solution consisting of two curves derived via the initial solution}
\label{fig:exp:multiple_split_triangles}
\end{figure}
\endgroup

$\alpha_{required}$ and $\alpha_{sharp}$ are designed to reduce the (non-asymptotic) running time of the algorithm.\\
When $\alpha_{required}$ is set to $0\degree$, then segments are never replaced because all angles are considered to be fine. Hence it does not make sense to pick a low value for $\alpha_{required}$. Setting the value to the other extreme value, $180\degree$, does not make sense either, because the number of unnecessary calculations increase. Choosing $\alpha_{required} = 90\degree$ did not have a negative effect on the final result. This makes sense, because the second step of the algorithm is designed to cope with the triangle problem, and the angles of the sharp corners in a triangle never exceed $90\degree$.\\
When $\alpha_{sharp}$ is set to $180\degree$, then the angles with alternative segments are considered to be too sharp, hence none of the segments will be replaced. If it is set to $0\degree$, then none of the segments will be excluded, and the algorithm evaluates for each of the $10$ neighbors of every sharp corner whether it makes sense to replace an existing segment with a new segment to the neighbor.

These parameters were designed to speed up the algorithm, but no evidence for such speed improvements were found during tests with 1000 and 10000 points. This might be caused by the fact that the majority of the alternative segments are ruled out during the initial steps of the "best point" finding algorithm that runs in constant time.

%TODO Parameter $\lambda$ (=length multiplier)
%TODO Parameter \textsc{minWeight}
%TODO Parameter 10 in $Adj_{p_1,10}$ - why 10?
%TODO \testsc{ClosenessFactor} Parameter 5f that determines closeness? 197-203 in MultipleCurves.java

%TODO Test case: Parallel lines

\subsubsection{Network reconstruction}

\subsection{Conclusion}

\section{Concluding remarks}
%TODO Multiple: future=Repeat step 1 with remaining points



\subsection{Future Work}
\bibliographystyle{plain}

\begin{thebibliography}{50}

\bibitem{crust}

Amenta, Nina, Marshall Bern, and Manolis Kamvysselis.
"A new Voronoi-based surface reconstruction algorithm."
\textit{Proceedings of the 25th annual conference on Computer graphics and interactive techniques}, 1998.

\bibitem{kruskal}
J.B. Kruskal.
On the shortest spanning subtree of a graph and the traveling salesman problem.
In \emph{Proceedings of the American Mathematical Society},7: 48-50, 1956.

\bibitem{chen}
D. Chen, L.J. Guibas, J. Hershberger, J. Sun.
Road Network Reconstruction for Organizing Paths.
In \emph{Proceedings  of  21st  ACM-SIAM  Symposium  on  Discrete  Algorithms}, 10: 1309-1320, 2010.

\bibitem{discur}
Zeng, Yong, et al. "A distance-based parameter free algorithm for curve reconstruction." \textit{Computer-Aided Design} 40.2: 210-222, 2008 .

\bibitem{gathan}
Dey, Tamal K., and Rephael Wenger. "Reconstruction curves with sharp corners." \textit{Proceedings of the sixteenth annual symposium on Computational geometry.} ACM, 2000.

\bibitem{convex}
Graham, R. L. "An efficient algorith for determining the convex hull of a finite planar set". \textit{Information processing letters}, 1(4), 132-133, 1972.

\end{thebibliography}







\end{document}
